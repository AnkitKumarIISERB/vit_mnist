# -*- coding: utf-8 -*-
"""mnist_vit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zu_nZy_zXEPnNmmsJNX_72kMJGNWrxmK
"""

!pip install -q torch torchvision transformers matplotlib

import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from transformers import ViTForImageClassification, ViTImageProcessor
import matplotlib.pyplot as plt

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Device being used:", device)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor()

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader  = DataLoader(test_dataset, batch_size=32)

images, labels = next(iter(train_loader))
plt.figure(figsize=(10,4))
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(images[i][0], cmap='gray')
    plt.title(f"Label: {labels[i].item()}")
    plt.axis('off')
plt.show()

from transformers import ViTForImageClassification, ViTImageProcessor


processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')


model = ViTForImageClassification.from_pretrained(
    'google/vit-base-patch16-224',
    num_labels=10,
    ignore_mismatched_sizes=True
model.to(device)

optimizer = optim.Adam(model.parameters(), lr=5e-5)
criterion = nn.CrossEntropyLoss()

epochs = 3  # enough for MNIST
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # Use processor and avoid rescaling (images already in [0,1])
        inputs = processor(images, return_tensors="pt", do_rescale=False).to(device)
        outputs = model(**inputs, labels=labels)
        loss = outputs.loss

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}")

model.eval()
correct, total = 0, 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        inputs = processor(images, return_tensors="pt", do_rescale=False).to(device)
        outputs = model(**inputs)
        preds = outputs.logits.argmax(dim=-1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

print(f"âœ… Test Accuracy: {100*correct/total:.2f}%")

images, labels = next(iter(test_loader))
inputs = processor(images, return_tensors="pt", do_rescale=False).to(device)
outputs = model(**inputs)
preds = outputs.logits.argmax(dim=-1).cpu()

plt.figure(figsize=(10,4))
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(images[i][0], cmap='gray')
    plt.title(f"Pred: {preds[i].item()}, True: {labels[i]}")
    plt.axis('off')
plt.show()

torch.save(model.state_dict(), "vit_mnist_tiny.pth")
print("Model saved as vit_mnist_tiny.pth")

